{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333ff910",
   "metadata": {},
   "source": [
    "# Sparse Sheaf Signal Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e5e5d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from vdm import VDM\n",
    "import cvxpy as cp\n",
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "from wavelet import Wavelet\n",
    "SEED = 6111983\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441826b3",
   "metadata": {},
   "source": [
    "##### Data\n",
    "\n",
    "Two synthetic datasets are generated: a cube point cloud and a fibonacci sphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfb55198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a cube in R^3 with uniformly random points\n",
    "N = 1000 # number of points in the cloud\n",
    "np.random.seed(6111983)\n",
    "cube_point_cloud = np.random.uniform(-0.5,0.5,N*3).reshape((N, 3)) # points\n",
    "\n",
    "# Function that computes a Fibonacci Sphere\n",
    "def fibonacci_sphere(N):\n",
    "    i = np.arange(N)\n",
    "    phi = (1+np.sqrt(5))/2\n",
    "    z = 1-2*i/(N-1)\n",
    "    theta = 2*np.pi*i/phi\n",
    "    r = np.sqrt(1-z*z)\n",
    "    x = r*np.cos(theta)\n",
    "    y = r*np.sin(theta)\n",
    "    return np.column_stack((x,y,z))\n",
    "\n",
    "# Generate fibonacci_sphere\n",
    "N = 1000 # number of points\n",
    "sphere_points = fibonacci_sphere(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5194cfc5",
   "metadata": {},
   "source": [
    "##### Vector Diffusion Mapping\n",
    "\n",
    "The following code uses the VDM class to build a tangent vector space bundle and find the alignment matrices, saved in a dictionary O. The functions ```coboundary_map``` and ```sheaf_laplacian``` build the sheaf laplacian using as restriction maps the alignment matrices Oij, and as node and edge stalks $\\mathbb{R}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d775875",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.15 # epsilon for the graph\n",
    "eps_pca = 0.1 # epsilon for the PCA\n",
    "k = 7 # number of nearest neighbors for the graph \n",
    "vdm2 = VDM(sphere_points,eps_pca,k) # VDM object\n",
    "G = vdm2.make_graph(method='radius') # create the graph with the radius method\n",
    "O = vdm2.make_alignment_matrices() # get alignment matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15d58a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sheaf Laplacian\n",
    "# Define edge orientation as follows: edge (i,j) has tail i and head j with i<j\n",
    "def coboundary_map(G,O,d):\n",
    "    '''\n",
    "    Function that builds the coboundary map of a sheaf given a graph G and O dictionary of alignment matrices Oij\n",
    "    Assumption: all restriction maps (alignment matrices) have the same dimension dxd\n",
    "    Inputs:\n",
    "    G = graph\n",
    "    O = dictionary of alignment matrices/ restriction maps (O[i][j] is the restriction map from node i to edge (i,j))\n",
    "    d = dimension of the matrices\n",
    "    Returns:\n",
    "    delta = coboundary map\n",
    "    '''\n",
    "    num_edges = G.number_of_edges()\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    delta = np.zeros((num_edges*d,num_nodes*d))\n",
    "    for edge_idx, edge in enumerate(G.edges()):\n",
    "        if edge[0]<edge[1]:\n",
    "            i = int(edge[0])\n",
    "            j = int(edge[1])\n",
    "        else:\n",
    "            i = int(edge[1])\n",
    "            j = int(edge[0])\n",
    "        delta[edge_idx*d:(edge_idx+1)*d, i*d:(i+1)*d] = O[i][j] # * G.get_edge_data(i,j)['weight']  # multiply by edge weight\n",
    "        delta[edge_idx*d:(edge_idx+1)*d, j*d:(j+1)*d] = - O[j][i] # * G.get_edge_data(j,i)['weight']\n",
    "    return delta\n",
    "\n",
    "def sheaf_laplacian(G,O,d):\n",
    "    delta = coboundary_map(G,O,d)\n",
    "    L = delta.T @ delta\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e42c8faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = sheaf_laplacian(G,O,vdm2.estimate_dim())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6c1fbf",
   "metadata": {},
   "source": [
    "##### Wavelets\n",
    "\n",
    "The code below creates a Wavelet object and uses some of the class methods to find wavelet coefficients.\n",
    "\n",
    "The kernel used by the wavelet is the following:\n",
    "\n",
    "$$\n",
    "g(x) = x^k \\cdot \\exp(-t \\cdot x^p)\n",
    "$$\n",
    "\n",
    "with default values\n",
    "\n",
    "* k=1\n",
    "* t=1\n",
    "* p=1\n",
    "\n",
    "that can be modified using the method ```Wavelet.set_kernel_parameters(k,t,p)```. Only non-negative values are allowed.\n",
    "\n",
    "This kernel was chosen such that $g(0)=0$ and $\\lim_{x \\rightarrow +\\infty} g(x) = 0$, to serve as a bandpass filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b2444be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([33.79120917, 33.79120917, 33.06391686, ...,  1.86879581,\n",
       "         1.18599063,  1.18599063], shape=(2000,)),\n",
       " array([[-2.82993843e-03, -1.75835884e-06, -3.31831942e-07, ...,\n",
       "         -7.95511670e-04, -5.30693815e-04, -7.24935232e-05],\n",
       "        [-6.81276315e-16, -2.82993788e-03,  9.63673389e-04, ...,\n",
       "         -1.10955098e-01, -9.37775755e-17, -5.25719140e-04],\n",
       "        [ 3.03464499e-03,  8.73110703e-04, -1.17047724e-03, ...,\n",
       "          9.99250732e-02, -1.70766241e-04,  4.47151446e-04],\n",
       "        ...,\n",
       "        [ 5.77087915e-07,  7.70750073e-08, -2.02938829e-05, ...,\n",
       "          1.46573498e-03, -2.94556395e-02, -1.00995470e-01],\n",
       "        [-1.26269743e-06, -1.56566149e-06, -5.80353599e-06, ...,\n",
       "         -1.52192162e-03, -5.70139489e-03,  9.99864796e-02],\n",
       "        [ 1.56487723e-06, -1.26172486e-06, -2.34912947e-05, ...,\n",
       "          2.16477251e-04, -1.01718801e-01, -1.95428821e-02]],\n",
       "       shape=(2000, 2000)))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a wavelet object and compute the Laplacian eigendecomposition\n",
    "wav = Wavelet(L)\n",
    "wav.get_eig_laplacian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa9bc680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wavelet coefficient of f for scale 0.5 and shift 0: 0.026248509956813472\n",
      "Value of the wavelet at node 0: 0.00864084425196611\n"
     ]
    }
   ],
   "source": [
    "# Find the wavelet coefficient of a signal f for a given scale and shift\n",
    "scale = 0.5\n",
    "shift = 0\n",
    "np.random.seed(SEED)\n",
    "f = np.random.randn(L.shape[0])\n",
    "print(f\"Wavelet coefficient of f for scale {scale} and shift {shift}: {wav.wavelet_coef(f,scale,shift)}\")\n",
    "# Show the value of the wavelet at node 2\n",
    "value = wav.wavelet(0,scale,shift)\n",
    "print(f\"Value of the wavelet at node 0: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b297f",
   "metadata": {},
   "source": [
    "##### Dictionaries\n",
    "\n",
    "The following code cells build three different dictionaries:\n",
    "\n",
    "1. This dictionary uses 7 scales [0.25, 0.5, 1, 2, 4, 8, 16] and shifts [1,...,L.shape[0]], with L being the Laplacian. All shifts are used due to the discrete nature of the spatial domain. Scale are selected using geometrical spacing to analyze signals at different resolutions. Small scales pick up on local features, larger scales on global ones. For every scale and shift parameter, a wavelet will be added to the dictionary, which will have dimension L.shape[0] x (num_scales*num_shifts).\n",
    "\n",
    "2. This dictionary was built by taking all shifts [1,...,L.shape[0]] and all scales [0.25, 0.5, 1, 2, 4, 8, 16], but instead of building wavelets for each pair of scale and shift parameters, it randomly selects combinations such that scale 0 is combined with all shifts, scale 1 with half of them, etc. The reasoning is that smaller scales are able to detect smaller details, so all shifts are required to cover the whole space. \n",
    "\n",
    "3. For this dictionary, geometric spacing was applied for the same reasons as in dictionary 1, but only for 4 scales, and using a more problem-specific range of scales, by king the reciprocals of the max and min eigenvalues of the Laplacian. We get again a dictionary of shape L.shape[0] x  (num_scales*num_shifts)\n",
    "\n",
    "All dictionaries are L2-normalized, but the normalization can be set to False in the ```wav.make_dictionary()``` and ```wav.make_dictionary_from_tuples()``` functions. The difference between these two functions is that the first one computes wavelets for every (scale,shift) pair given lists of scales and shifts, while the second iterates over a list of tuples directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8271815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICTIONARY 1: scales and shifts\n",
    "num_scales1 = 7\n",
    "scales1 = [2**(j-2) for j in range(num_scales1)]\n",
    "num_shifts1 = L.shape[0]\n",
    "shifts1 = [i for i in range(num_shifts1)]\n",
    "# Build the dictionary of wavelets\n",
    "wav_dict1 = wav.make_dictionary(scales1,shifts1)\n",
    "\n",
    "# DICTIONARY 2: scales and shifts\n",
    "# Scale set\n",
    "num_scales2 = 7\n",
    "scales2 = [2**(j-2) for j in range(num_scales2)]\n",
    "# Shift set\n",
    "shifts_per_scale = {\n",
    "    scales2[0]: L.shape[0],\n",
    "    scales2[1]: L.shape[0]//2,\n",
    "    scales2[2]: L.shape[0]//4,\n",
    "    scales2[3]: L.shape[0]//8,\n",
    "    scales2[4]: L.shape[0]//16,\n",
    "    scales2[5]: L.shape[0]//32,\n",
    "    scales2[6]: L.shape[0]//64,\n",
    "}\n",
    "shifts2 = {s: np.random.choice(L.shape[0], shifts_per_scale[s], replace=False) for s in scales2}\n",
    "# Make scale_shift tuple list\n",
    "scale_shift_tuples = [(s, shifts2[s][i]) for s in scales2 for i in range(shifts_per_scale[s])]\n",
    "# Build the dictionary of wavelets\n",
    "wav_dict2 = wav.make_dictionary_from_tuples(scale_shift_tuples)\n",
    "\n",
    "# DICTIONARY 3: scales and shifts\n",
    "# Scale set\n",
    "lambda_max = np.max(wav.eigvals)\n",
    "lambda_min = np.min(wav.eigvals[wav.eigvals>0])\n",
    "s_min = 1/lambda_max\n",
    "s_max = 1/lambda_min\n",
    "num_scales3 = 4\n",
    "scales3 = np.geomspace(s_min, s_max, num_scales3)\n",
    "# Shift set\n",
    "num_shifts3 = L.shape[0]\n",
    "shifts3 = [i for i in range(num_shifts3)]\n",
    "# Make a dictionary from wavelets with scales in scales3 and shifts in [1:N]\n",
    "wav_dict3 = wav.make_dictionary(scales3,shifts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6866175d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual coherence 1: 0.9999999998558362\n",
      "Mutual coherence 2: 0.999999155031966\n",
      "Mutual coherence 3: 0.9981787052765341\n"
     ]
    }
   ],
   "source": [
    "# Function that computes the coherence of a dictionary\n",
    "def mutual_coherence(D):\n",
    "    D_norm = D / np.linalg.norm(D, axis=0, keepdims=True) # Column-wise normalization\n",
    "    gram = D_norm.T @ D_norm # Gram matrix\n",
    "    np.fill_diagonal(gram, 0)\n",
    "    mu = np.max(np.abs(gram))\n",
    "    return mu\n",
    "\n",
    "# Print coherences\n",
    "mu1 = mutual_coherence(wav_dict1)\n",
    "print(\"Mutual coherence 1:\", mu1)\n",
    "mu2 = mutual_coherence(wav_dict2)\n",
    "print(\"Mutual coherence 2:\", mu2)\n",
    "mu3 = mutual_coherence(wav_dict3)\n",
    "print(\"Mutual coherence 3:\", mu3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cf7677",
   "metadata": {},
   "source": [
    "##### Sparse Optimization Problem\n",
    "\n",
    "Given an overcomplete dictionary $A$ and a signal $y$, finding the best sparse representation of $y$ is equivalent to solving\n",
    "\n",
    "$$\n",
    "\\min_x \\|x\\|_0 \\quad \\text{s.t.} \\quad Ax=y\n",
    "$$\n",
    "\n",
    "Since this problem is NP-hard, we try to solve this problem instead:\n",
    "\n",
    "**LASSO**\n",
    "\n",
    "$$\n",
    "\\min_x \\frac{1}{2} \\| Ax-y \\|_2^2 + \\lambda \\|x\\|_1\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "* A = wavelet dictionary\n",
    "* y = signal\n",
    "* x = sparse representation of the signal that we want to find\n",
    "* $\\lambda$ = regularization parameter\n",
    "\n",
    "The wavelet dictionary is **highly overcomplete and coherent**, so greedy and first-order methods are unstable. Since the problem is convex and of moderate size, I used the global convex solver CVXPY to find the sparse signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87677a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsification error: 7.99716456733055e-08\n"
     ]
    }
   ],
   "source": [
    "# Test signal sparsification\n",
    "signal = 2 * wav_dict1[:,20] + 19 * wav_dict1[:,1900] - 4 * wav_dict1[:,3000]\n",
    "sparsified_signal = wav.sparse_signal(signal,wav_dict1) # uses OMP\n",
    "print(f'Sparsification error: {np.linalg.norm(wav_dict1 @ sparsified_signal - signal, ord=2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bfb9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some signals\n",
    "\n",
    "signal11 = 2 * wav_dict1[:,20] + 19 * wav_dict1[:,1900] - 4 * wav_dict1[:,3000]\n",
    "signal12 = 2 * wav_dict2[:,20] + 19 * wav_dict2[:,1900] - 4 * wav_dict2[:,3000]\n",
    "signal13 = 2 * wav_dict3[:,20] + 19 * wav_dict3[:,1900] - 4 * wav_dict3[:,3000]\n",
    "\n",
    "signal21 = 23 * wav_dict1[:,1432] - 11 * wav_dict1[:,5555] + 17 * wav_dict1[:,7644]\n",
    "signal22 = 23 * wav_dict2[:,1432] - 11 * wav_dict2[:,2378] + 17 * wav_dict2[:,3338]\n",
    "signal23 = 23 * wav_dict3[:,1432] - 11 * wav_dict3[:,5555] + 17 * wav_dict3[:,7644]\n",
    "\n",
    "random_signal = np.random.randn(L.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c370dbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sparse signal representations\n",
    "sparse_signal11 = wav.sparse_signal(signal11,wav_dict1)\n",
    "sparse_signal12 = wav.sparse_signal(signal12,wav_dict2)\n",
    "sparse_signal13 = wav.sparse_signal(signal13,wav_dict3)\n",
    "\n",
    "sparse_signal21 = wav.sparse_signal(signal21,wav_dict1)\n",
    "sparse_signal22 = wav.sparse_signal(signal22,wav_dict2)\n",
    "sparse_signal23 = wav.sparse_signal(signal23,wav_dict3)\n",
    "\n",
    "sparse_signal_random = wav.sparse_signal(random_signal,wav_dict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e971ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error signal 1 dictionary 1: 2.5621543119148667e-09\n",
      "Error signal 1 dictionary 2: 1.5251579018258714e-09\n",
      "Error signal 1 dictionary 3: 3.796555578905782e-08\n",
      "Error signal 2 dictionary 1: 1.4237740259160458e-07\n",
      "Error signal 2 dictionary 2: 1.3483902104331406e-08\n",
      "Error signal 2 dictionary 3: 8.863916155603043e-09\n",
      "Error random: 1.1105489781347665e-06\n"
     ]
    }
   ],
   "source": [
    "# Recovery Errors\n",
    "err11 = np.linalg.norm(wav_dict1 @ sparse_signal11 - signal11, ord=2)\n",
    "err12 = np.linalg.norm(wav_dict2 @ sparse_signal12 - signal12, ord=2)\n",
    "err13 = np.linalg.norm(wav_dict3 @ sparse_signal13 - signal13, ord=2)\n",
    "\n",
    "err21 = np.linalg.norm(wav_dict1 @ sparse_signal21 - signal21, ord=2)\n",
    "err22 = np.linalg.norm(wav_dict2 @ sparse_signal22 - signal22, ord=2)\n",
    "err23 = np.linalg.norm(wav_dict3 @ sparse_signal23 - signal23, ord=2)\n",
    "\n",
    "err_random = np.linalg.norm(wav_dict3 @ sparse_signal_random - random_signal, ord=2)\n",
    "\n",
    "print(\"Error signal 1 dictionary 1:\", err11)\n",
    "print(\"Error signal 1 dictionary 2:\", err12)\n",
    "print(\"Error signal 1 dictionary 3:\", err13)\n",
    "\n",
    "print(\"Error signal 2 dictionary 1:\", err21)\n",
    "print(\"Error signal 2 dictionary 2:\", err22)\n",
    "print(\"Error signal 2 dictionary 3:\", err23)\n",
    "\n",
    "print(\"Error random:\", err_random)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
